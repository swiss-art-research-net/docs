@incollection{bruseker_cultural_2017,
  title = {Cultural {{Heritage Data Management}}: {{The Role}} of {{Formal Ontology}} and {{CIDOC CRM}}},
  shorttitle = {Cultural {{Heritage Data Management}}},
  booktitle = {Heritage and {{Archaeology}} in the {{Digital Age}}: {{Acquisition}}, {{Curation}}, and {{Dissemination}} of {{Spatial Cultural Heritage Data}}},
  author = {Bruseker, George and Carboni, Nicola and Guillem, Ana{\"i}s},
  editor = {Vincent, Matthew L. and {L{\'o}pez-Menchero Bendicho}, V{\'i}ctor Manuel and Ioannides, Marinos and Levy, Thomas E.},
  year = {2017},
  pages = {93--131},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-65370-9_6},
  url = {https://doi.org/10.1007/978-3-319-65370-9_6},
  urldate = {2025-04-04},
  abstract = {Building models for integrating the diverse data generated in Cultural Heritage disciplines is a long-term challenge both for securing presently generated knowledge and for making it progressively more widely accessible and interoperable into the future. This chapter reviews the multiple approaches undertaken to address this problem, finally proposing CIDOC CRM as the most robust solution for information integration in CH. The chapter begins by outlining the data challenge specific to the field and the main approaches that can be taken in facing it. Within this frame, it distinguishes knowledge engineering and formal ontology from other information modelling techniques as the necessary approach for tackling the broader data integration problem. It then outlines the basic principles of CIDOC CRM, the ISO standard formal ontology for CH. From there, an overview is given of some of the work that has been done both theoretically and in practice over the past five years in developing and implementing CRM as a practical data integration strategy in CH, particularly looking at model extensions to handle knowledge provenance across various disciplines and typical documentation and reasoning activities, as well as at successful implementation projects. Lastly, it summarizes the present potentials and challenges for using CIDOC CRM for solving the CH data management and integration puzzle. The intended audience of this chapter are specialists from all backgrounds within the broader domain of CH with an interest in data integration and CIDOC CRM.},
  isbn = {978-3-319-65370-9},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/94BET2IZ/Bruseker et al_2017_Cultural Heritage Data Management.pdf}
}

@article{bruseker_semantic_2025,
  title = {The {{Semantic Reference Data Modelling Method}}: {{Creating Understandable}}, {{Reusable}} and {{Sustainable Semantic Data Models}}},
  shorttitle = {The {{Semantic Reference Data Modelling Method}}},
  author = {Bruseker, George and Carboni, Nicola and Fielding, Matthew and Nenova, Denitsa and H{\"a}nsli, Thomas},
  year = {2025},
  month = mar,
  journal = {Journal of Open Humanities Data},
  volume = {11},
  number = {1},
  issn = {2059-481X},
  doi = {10.5334/johd.282},
  url = {https://openhumanitiesdata.metajnl.com/articles/10.5334/johd.282},
  urldate = {2025-06-04},
  abstract = {As ontologies grow in complexity and breadth, domain experts often struggle to understand their intricacies without the assistance of semantic experts. As a result, the ontologies themselves can become significant obstacles in constructing reusable and consistent knowledge graphs of their data following these standards. To address these challenges, this contribution presents the Semantic Reference Data Model (SRDM) modelling method, a protocol that offers a practical approach to (i) simplifying ontological complexity, (ii) standardising semantic patterns and (iii) facilitating the creation of new knowledge graphs. SRDM provides a solution for overcoming conceptual challenges by offering a catalogue of entity-based templates, whereby recognisable entities within a domain are documented in single templates composed of ready-made and distinct ontological patterns covering the entity\&rsquo;s most documented attributes. The limited number of elements available, the use of domain-specific language, and the correspondence between documented objects and real-world items make the SRDMs particularly easy to grasp, helping bridge the gap between semantic and domain experts. A case study is used to illustrate the framework\&rsquo;s application in the cultural sector, specifically highlighting the advantages obtained in documentation, data consistency, and external data ingestion. The case study demonstrates how SRDMs can vastly simplify the creation and management of knowledge graphs, helping Digital Humanities and Cultural Heritage communities easily share essential and useful datasets.},
  langid = {american},
  file = {/Users/mromanel/Zotero/storage/CBH3TZ6U/Bruseker et al. - 2025 - The Semantic Reference Data Modelling Method Crea.pdf}
}

@article{cetinic_understanding_2022,
  title = {Understanding and {{Creating Art}} with {{AI}}: {{Review}} and {{Outlook}}},
  shorttitle = {Understanding and {{Creating Art}} with {{AI}}},
  author = {Cetinic, Eva and She, James},
  year = {2022},
  month = may,
  journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
  volume = {18},
  number = {2},
  pages = {1--22},
  issn = {1551-6857, 1551-6865},
  doi = {10.1145/3475799},
  url = {https://dl.acm.org/doi/10.1145/3475799},
  urldate = {2024-11-12},
  abstract = {Technologies related to artificial intelligence (AI) have a strong impact on the changes of research and creative practices in visual arts. The growing number of research initiatives and creative applications that emerge in the intersection of AI and art motivates us to examine and discuss the creative and explorative potentials of AI technologies in the context of art. This article provides an integrated review of two facets of AI and art: (1) AI is used for art analysis and employed on digitized artwork collections, or (2) AI is used for creative purposes and generating novel artworks. In the context of AI-related research for art understanding, we present a comprehensive overview of artwork datasets and recent works that address a variety of tasks such as classification, object detection, similarity retrieval, multimodal representations, and computational aesthetics, among others. In relation to the role of AI in creating art, we address various practical and theoretical aspects of AI Art and consolidate related works that deal with those topics in detail. Finally, we provide a concise outlook on the future progression and potential impact of AI technologies on our understanding and creation of art.},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/U3CGXYF2/Cetinic_She_2022_Understanding and Creating Art with AI.pdf}
}

@article{cornut_annotations_2023,
  title = {Annotations as {{Knowledge Practices}} in {{Image Archives}}: {{Application}} of {{Linked Open Usable Data}} and {{Machine Learning}}},
  shorttitle = {Annotations as {{Knowledge Practices}} in {{Image Archives}}},
  author = {Cornut, Murielle and Raemy, Julien Antoine and Spiess, Florian},
  year = {2023},
  month = nov,
  journal = {J. Comput. Cult. Herit.},
  volume = {16},
  number = {4},
  pages = {80:1--80:19},
  issn = {1556-4673},
  doi = {10.1145/3625301},
  url = {https://dl.acm.org/doi/10.1145/3625301},
  urldate = {2024-09-25},
  abstract = {We reflect on some of the preliminary findings of the Participatory Knowledge Practices in Analogue and Digital Image Archives (PIA) research project around annotations of photographic archives from the Swiss Society for Folklore Studies (SSFS) as knowledge practices, the underlying technological decisions, and their impact. The aim is not only to seek more information but to find new approaches of understanding the way in which people's memory relate to the collective, public form of archival memory and ultimately how users figure in and shape the digital archive.We provide a proof-of-concept workflow based on automatically generated annotations comprising 53,481 photos that were subjected to object detection using Faster R-CNN Inception ResNet V2. Of the detected objects, 184,609 have a detection score greater than 0.5, 123,529 have a score greater than 0.75, and 88,442 have a score greater than 0.9. A threshold of 0.75 was set for the dissemination of our annotations, compatible with the W3C Web Annotation Data Model (WADM) and embedded in our IIIF Manifests.In the near future, the workflow will be upgraded to allow for the co-existence of various, and occasionally conflicting, assertions made by both human and machine users. We believe that Linked Open Usable Data (LOUD) standards should be used to improve the sustainability of such an ecosystem and to foster collaboration between actors in cultural heritage.},
  file = {/Users/mromanel/Zotero/storage/FQV9EHPZ/Cornut et al. - 2023 - Annotations as Knowledge Practices in Image Archiv.pdf}
}

@article{daga_data_2024,
  title = {Data Journeys: {{Explaining AI}} Workflows through Abstraction},
  shorttitle = {Data Journeys},
  author = {Daga, Enrico and Groth, Paul},
  year = {2024},
  month = oct,
  journal = {Semantic Web},
  volume = {15},
  number = {4},
  pages = {1057--1083},
  publisher = {SAGE Publications},
  issn = {1570-0844},
  doi = {10.3233/SW-233407},
  url = {https://journals.sagepub.com/action/showAbstract},
  urldate = {2025-04-02},
  abstract = {Artificial intelligence systems are not simply built on a single dataset or trained model. Instead, they are made by complex data science workflows involving multiple datasets, models, preparation scripts, and algorithms. Given this complexity, in order to understand these AI systems, we need to provide explanations of their functioning at higher levels of abstraction. To tackle this problem, we focus on the extraction and representation of data journeys from these workflows. A data journey is a multi-layered semantic representation of data processing activity linked to data science code and assets. We propose an ontology to capture the essential elements of a data journey and an approach to extract such data journeys. Using a corpus of Python notebooks from Kaggle, we show that we are able to capture high-level semantic data flow that is more compact than using the code structure itself. Furthermore, we show that introducing an intermediate knowledge graph representation outperforms models that rely only on the code itself. Finally, we report on a user survey to reflect on the challenges and opportunities presented by computational data journeys for explainable AI.},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/PI3SYMJ3/confalonieri-et-al-2023-data-journeys-explaining-ai-workflows-through-abstraction.pdf}
}

@article{daquino_photo_2024,
  title = {Photo {{Archives}} and {{Linked Open Data}}. {{The Added Value}}},
  author = {Daquino, Marilena},
  year = {2024},
  month = aug,
  journal = {Open Library of Humanities},
  volume = {10},
  number = {2},
  publisher = {Open Library of Humanities},
  issn = {2056-6700},
  doi = {10.16995/olh.15232},
  url = {https://olh.openlibhums.org/article/id/15232/},
  urldate = {2024-09-13},
  abstract = {In the last two decades, cultural heritage institutions have been revisiting the way they publish their data. Due to the rise of Semantic Web technologies and graph-based search engines, the shift in the technology stack has required many to reconsider also the way their data were organised. The appreciable byproduct of this phenomenon has been the development of data literacy skills among cataloguers, archivists, and collection managers, who were in turn promised a revamp of the institution's image in terms of authoritativeness (due to the improved data quality) and attractiveness towards patrons (due to the enhanced search capabilities). In this article we describe how photo archives have embraced such a new paradigm, and we discuss benefits and limitations, moving from a representative example, i.e., ZERI \&amp; LODe, a project devoted to the publication of the catalogue of the Federico Zeri Photo Archive into Linked Open Data. The focus of the analysis is the (missed?) added value promised by Semantic Web technologies and the Open Data business model to cataloguers, scholars, and arts enthusiasts.\&nbsp;},
  copyright = {Copyright: {\copyright} 2024 The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/HCTG359N/Daquino - 2024 - Photo Archives and Linked Open Data. The Added Val.pdf}
}

@article{delmas-glass_fostering_2020,
  title = {Fostering a Community of {{PHAROS}} Scholars through the Adoption of Open Standards},
  author = {{Delmas-Glass}, Emmanuelle and Sanderson, Robert},
  year = {2020},
  month = jan,
  journal = {Art Libraries Journal},
  volume = {45},
  number = {1},
  pages = {19--23},
  issn = {0307-4722, 2059-7525},
  doi = {10.1017/alj.2019.32},
  url = {https://www.cambridge.org/core/journals/art-libraries-journal/article/fostering-a-community-of-pharos-scholars-through-the-adoption-of-open-standards/836554F24963C7B430DE3016E51FA8DA},
  urldate = {2024-10-03},
  abstract = {The PHAROS consortium is adopting the Linked Art data model to make its descriptions of photo archives collections available as Linked Open Data to further support scholars in their research. Linked Art is both a community and a data model. As an international community, it works together to create a shared data model to describe art. As a data model, it is a data profile of the CIDOC Conceptual Reference Model and using Linked Open Data techniques. The goal of Linked Art is to enable museums and developers to engage in LOD initiatives more easily by providing them with shared data modelling decisions and consistent design principles.},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/TX5CFU6P/Delmas-Glass_Sanderson_2020_Fostering a community of PHAROS scholars through the adoption of open standards.pdf}
}

@inproceedings{doerr_framework_2014,
  title = {A {{Framework}} for {{Maintaining Provenance Information}} of {{Cultural Heritage 3D-models}}},
  booktitle = {Proceedings of the {{EVA London}} 2014 on {{Electronic Visualisation}} and the {{Arts}}},
  author = {Doerr, Martin and Chrysakis, Ioannis and Axaridou, Anastasia and Theodoridou, Maria and Georgis, Christos and Maravelakis, Emmanuel},
  year = {2014},
  month = jul,
  series = {{{EVA London}} 2014},
  pages = {267--274},
  publisher = {BCS},
  address = {Swindon, GBR},
  doi = {10.14236/ewic/eva2014.32},
  url = {https://doi.org/10.14236/ewic/eva2014.32},
  urldate = {2024-09-17},
  abstract = {The advances in 3D digitizing technology have found significant application in the Cultural Heritage domain. The systematic large-scale production of digital cultural objects, the diversity of the processes involved and the complexity of describing historical relationships among them imposes the need for innovative knowledge management to handle all the semantic information in order to monitor, manage and document the origins and derivation of digital products. Flexibility is also very important for the enrichment and sharing of the acquired knowledge. The latter can be exploited by all members of the Cultural Heritage scientific community who can take advantage of the recorded provenance information for evaluating the 3D representation, tracking reliability of production, detecting tolerance and accuracy in acquisition and processing phases, documenting digitisation techniques, studying evidence of historic and cultural events. In this paper we present a framework that supports the documentation, archiving and dissemination of data and metadata of 3D digital cultural heritage objects, enhancing the OAIS approach by permitting the ingest of all the involved data, not only the final result, during a workflow progress.},
  isbn = {978-1-78017-285-9},
  file = {/Users/mromanel/Zotero/storage/FVMIMJHA/Doerr et al_2014_A Framework for Maintaining Provenance Information of Cultural Heritage.pdf}
}

@techreport{europeana_ai_2023,
  title = {{{AI}} in Relation to {{GLAMs Task Force}}: {{Report}} and {{Recommendations}}},
  year = {2023},
  month = sep,
  institution = {Europeana},
  url = {https://pro.europeana.eu/project/ai-in-relation-to-glams},
  file = {/Users/mromanel/Zotero/storage/NPMXFCHJ/AI IN RELATION TO GLAMS TASK FORCE Report and reco.pdf}
}

@article{fiorucci_machine_2020,
  title = {Machine {{Learning}} for {{Cultural Heritage}}: {{A Survey}}},
  shorttitle = {Machine {{Learning}} for {{Cultural Heritage}}},
  author = {Fiorucci, Marco and Khoroshiltseva, Marina and Pontil, Massimiliano and Traviglia, Arianna and Del Bue, Alessio and James, Stuart},
  year = {2020},
  month = may,
  journal = {Pattern Recognition Letters},
  volume = {133},
  pages = {102--108},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2020.02.017},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865520300532},
  urldate = {2024-10-22},
  abstract = {The application of Machine Learning (ML) to Cultural Heritage (CH) has evolved since basic statistical approaches such as Linear Regression to complex Deep Learning models. The question remains how much of this actively improves on the underlying algorithm versus using it within a `black box' setting. We survey across ML and CH literature to identify the theoretical changes which contribute to the algorithm and in turn them suitable for CH applications. Alternatively, and most commonly, when there are no changes, we review the CH applications, features and pre/post-processing which make the algorithm suitable for its use. We analyse the dominant divides within ML, Supervised, Semi-supervised and Unsupervised, and reflect on a variety of algorithms that have been extensively used. From such an analysis, we give a critical look at the use of ML in CH and consider why CH has only limited adoption of ML.},
  keywords = {Artificial Intelligence,Cultural Heritage,Digital Humanities,Machine Learning},
  file = {/Users/mromanel/Zotero/storage/4722H8D6/Fiorucci et al_2020_Machine Learning for Cultural Heritage.pdf}
}

@inproceedings{foka_computer_nodate,
  title = {Computer {{Vision Applications}} for {{Art History}}: {{Reflections}} and Paradigms for Future Research},
  shorttitle = {Computer {{Vision Applications}} for {{Art History}}},
  author = {Foka, Amalia F.},
  doi = {10.14236/ewic/EVA2021.12},
  url = {https://www.scienceopen.com/hosted-document?doi=10.14236/ewic/EVA2021.12},
  urldate = {2024-10-09},
  abstract = {{$<$}p class="first" id="d1036819e63"{$>$}One of the contributing factors to the continuing debate among art historians over             the use of computational methods in art history research is that they do not consider             the core of today's art history research questions. The lack of close collaboration             between the two involved research communities makes the definition of contemporary             art-historical methods as well-defined computer vision problems extremely difficult.             For that purpose, it is devised as a methodology to study articles in art history             journals from a computer science perspective. The objective is to identify which image             features art historians utilise within their research and describe them in immediate             and meaningful terms to the computer vision research community. Finally, some paradigms             that could serve as a new starting point for exploring how computer vision applications             for art history can address the core of today's art history research are given.          {$<$}/p{$>$}},
  file = {/Users/mromanel/Zotero/storage/Q25TRY9I/Foka - Computer Vision Applications for Art History Refl.pdf}
}

@misc{ghattas_analysing_nodate,
  title = {Analysing the {{Use}} of {{Colors}} in {{Historical Prints}} and {{Drawings}}},
  author = {Ghattas, Andre},
  url = {https://www.sari.uzh.ch/en/Insights/Analysing-the-Use-of-Colors-in-Historical-Prints-and-Drawings.html},
  urldate = {2024-09-13},
  abstract = {Analysing the Use of Colors in Historical Prints and Drawings},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/6HLK8XPN/Analysing-the-Use-of-Colors-in-Historical-Prints-and-Drawings.html}
}

@inproceedings{hennicke_sustainable_2024,
  title = {Sustainable {{Semantics}} for {{Sustainable Research Data}}},
  booktitle = {Proceedings of the {{First International Workshop}} of {{Semantic Digital Humanities}} ({{SemDH}} 2024)},
  author = {Hennicke, Steffen and Belouin, Pascal and Hajj, Hassan El and Fielding, Matthew and Casties, Robert and Pham, Kim},
  editor = {Bruns, Oleksandra and Poltronieri, Andrea and Stork, Lise and Tietz, Tabea},
  year = {2024},
  month = may,
  series = {{{CEUR Workshop Proceedings}}},
  volume = {3724},
  publisher = {CEUR},
  address = {Hersonissos, Greece},
  issn = {1613-0073},
  url = {https://ceur-ws.org/Vol-3724/#short3},
  urldate = {2025-02-28},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/RG2QU8Z5/Hennicke et al. - 2024 - Sustainable Semantics for Sustainable Research Dat.pdf}
}

@article{joyeux-prunel_digital_2024,
  title = {Digital Humanities in the Era of Digital Reproducibility: Towards a Fairest and Post-Computational Framework},
  shorttitle = {Digital Humanities in the Era of Digital Reproducibility},
  author = {{Joyeux-Prunel}, B{\'e}atrice},
  year = {2024},
  month = apr,
  journal = {International Journal of Digital Humanities},
  volume = {6},
  number = {1},
  pages = {23--43},
  issn = {2524-7840},
  doi = {10.1007/s42803-023-00079-6},
  url = {https://doi.org/10.1007/s42803-023-00079-6},
  urldate = {2025-04-28},
  abstract = {Reproducibility has become a requirement in the hard sciences, and its adoption is gradually extending to the digital humanities. The FAIR criteria and the publication of data papers are both indicative of this trend. However, the question that arises is whether the strict prerequisites of digital reproducibility serve only to exclude digital humanities from broader humanities scholarship. Instead of adopting a binary approach, an alternative method acknowledges the unique features of the objects, inquiries, and techniques of the humanities, including digital humanities, as well as the social and historical contexts in which the concept of reproducibility has developed in the human sciences. In the first part of this paper, I propose to examine the historical and disciplinary context in which the concept of reproducibility has developed within the human sciences, and the disciplinary struggles involved in this process, especially for art history and literature studies. In the second part, I will explore the question of reproducibility through two art history research projects that utilize various computational methods. I argue that issues of corpus, method, and interpretation cannot be separated, rendering a procedural definition of reproducibility impractical. Consequently, I propose the adoption of `post-computational reproducibility', which is based on FAIREST criteria as far as digital corpora are concerned (FAIR\,+\,Ethics and Expertise, Source mention\,+\,Time-Stamp), but extended to include further sources that confirm computational results with other non-computational methodologies.},
  langid = {english},
  keywords = {Data,Digital art history,Digital humanities,Distant reading,FAIR principles,Reproducibility},
  file = {/Users/mromanel/Zotero/storage/HKT89NKK/Joyeux-Prunel - 2024 - Digital humanities in the era of digital reproduci.pdf}
}

@article{kim_exploring_2024,
  title = {Exploring the {{Application}} of {{Artificial Intelligence}} and {{Machine Learning}} in {{GLAM Collections}}},
  author = {Kim, Jeonghyun and Chen, Haihua and Yang, Le and Simic, Julia},
  year = {2024},
  journal = {Proceedings of the Association for Information Science and Technology},
  volume = {61},
  number = {1},
  pages = {782--785},
  issn = {2373-9231},
  doi = {10.1002/pra2.1101},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pra2.1101},
  urldate = {2024-10-17},
  abstract = {In recent years, considerable work has been done on the application of artificial intelligence (AI) and machine learning (ML) in the realm of cultural heritage. The purpose of this panel is to address the following questions: What is the current understanding and implementation status of AI/ML in GLAM collections? What are the associated concerns and challenges in real cases? What does this entail in applying AI/ML in the field of computational archives? To address these questions, the panelists will present: 1) use cases of AI/ML technologies applied within GLAM collections, 2) findings from a systematic review of literature on AI/ML in GLAM collections, and 3) insights from semi-structured interviews with archival practitioners on their perspectives on AI/ML. Following the panelists' presentations, an interactive discussion session will be conducted to delve deeper into the topics discussed.},
  copyright = {87th Annual Meeting of the Association for Information Science \& Technology {\textbar} Oct. 25 -- 29, 2024 {\textbar} Calgary, AB, Canada},
  langid = {english},
  keywords = {Artificial Intelligence,Cultural Heritage Institutions,Digital Collections,GLAM,Machine Learning},
  file = {/Users/mromanel/Zotero/storage/T424EKUX/Kim et al_2024_Exploring the Application of Artificial Intelligence and Machine Learning in.pdf}
}

@article{klic_linked_2023,
  title = {Linked {{Open Images}}: {{Visual Similarity}} for the {{Semantic Web}}},
  author = {Klic, Lukas},
  year = {2023},
  journal = {Semantic Web},
  url = {https://www.semantic-web-journal.net/content/linked-open-images-visual-similarity-semantic-web-0},
  urldate = {2024-09-13},
  file = {/Users/mromanel/Zotero/storage/IAUJU8GF/sw-14-sw212893.pdf}
}

@incollection{kremers_visual_2020,
  title = {Visual {{Content Analysis}} and {{Linked Data}} for {{Automatic Enrichment}} of {{Architecture-Related Images}}},
  booktitle = {Digital {{Cultural Heritage}}},
  author = {Mager, Tino and Khademi, Seyran and Siebes, Ronald and Hein, Carola and Boer, Victor De and Gemert, Jan Van},
  editor = {Kremers, Horst},
  year = {2020},
  pages = {279--293},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-15200-0_18},
  url = {http://link.springer.com/10.1007/978-3-030-15200-0_18},
  urldate = {2024-09-24},
  isbn = {978-3-030-15198-0 978-3-030-15200-0},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/AERW4566/Mager et al_2020_Visual Content Analysis and Linked Data for Automatic Enrichment of.pdf}
}

@inproceedings{lee_newspaper_2020,
  title = {The {{Newspaper Navigator Dataset}}: {{Extracting Headlines}} and {{Visual Content}} from 16 {{Million Historic Newspaper Pages}} in {{Chronicling America}}},
  shorttitle = {The {{Newspaper Navigator Dataset}}},
  booktitle = {Proceedings of the 29th {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Lee, Benjamin Charles Germain and Mears, Jaime and Jakeway, Eileen and Ferriter, Meghan and Adams, Chris and Yarasavage, Nathan and Thomas, Deborah and Zwaard, Kate and Weld, Daniel S.},
  year = {2020},
  month = oct,
  series = {{{CIKM}} '20},
  pages = {3055--3062},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3340531.3412767},
  url = {https://dl.acm.org/doi/10.1145/3340531.3412767},
  urldate = {2024-10-29},
  abstract = {Chronicling America is a product of the National Digital Newspaper Program, a partnership between the Library of Congress and the National Endowment for the Humanities to digitize historic American newspapers. Over 16 million pages have been digitized to date, complete with high-resolution images and machine-readable METS/ALTO OCR. Of considerable interest to Chronicling America users is a semantified corpus, complete with extracted visual content and headlines. To accomplish this, we introduce a visual content recognition model trained on bounding box annotations collected as part of the Library of Congress's Beyond Words crowdsourcing initiative and augmented with additional annotations including those of headlines and advertisements. We describe our pipeline that utilizes this deep learning model to extract 7 classes of visual content: headlines, photographs, illustrations, maps, comics, editorial cartoons, and advertisements, complete with textual content such as captions derived from the METS/ALTO OCR, as well as image embeddings. We report the results of running the pipeline on 16.3 million pages from the Chronicling America corpus and describe the resulting Newspaper Navigator dataset, the largest dataset of extracted visual content from historic newspapers ever produced. The Newspaper Navigator dataset, finetuned visual content recognition model, and all source code are placed in the public domain for unrestricted re-use.},
  isbn = {978-1-4503-6859-9},
  file = {/Users/mromanel/Zotero/storage/NY8YDHZB/Lee et al. - 2020 - The Newspaper Navigator Dataset Extracting Headli.pdf}
}

@article{lorenzini_assessing_2021,
  title = {On Assessing Metadata Completeness in Digital Cultural Heritage Repositories},
  author = {Lorenzini, Matteo and Rospocher, Marco and Tonelli, Sara},
  year = {2021},
  month = oct,
  journal = {Digital Scholarship in the Humanities},
  volume = {36},
  number = {Supplement\_2},
  pages = {ii182-ii188},
  issn = {2055-7671},
  doi = {10.1093/llc/fqab036},
  url = {https://doi.org/10.1093/llc/fqab036},
  urldate = {2024-10-09},
  abstract = {Metadata allows access to a wide variety of cultural heritage resources made available through repositories, digital libraries, and catalogues. Usually taking the form of a structured set of descriptive elements, metadata assist in the identification, location, processing, tracking, preserving, sharing, and retrieval of information, while facilitating content and access management. However, low metadata quality, such as the lack of mandatory information, incorrect information, or inconsistency, is still an open issue in many repositories. In this article, we present our ongoing work aiming at automatizing the metadata quality analysis, and the preliminary results on metadata completeness for the Italian digital library `Cultura Italia'.},
  file = {/Users/mromanel/Zotero/storage/EAYCNIGH/Lorenzini et al. - 2021 - On assessing metadata completeness in digital cult.pdf}
}

@misc{moreux_dealing_2021,
  title = {Dealing with Data Issues for {{AI-supported Image Analysis}} in {{Cultural Heritage}}: Concrete Cases and Challenges},
  author = {Moreux, Jean-Phillipe and Berm{\`e}s, Emmanuelle and Isaac, Antoine and {Jos{\'e} E., Cejudo}},
  year = {2021},
  address = {Paris},
  file = {/Users/mromanel/Zotero/storage/IYRB5S2P/Moreux et al. - 2021 - Dealing with data issues for AI-supported Image An.pdf}
}

@techreport{noauthor_definition_2022,
  title = {Definition of {{CRMdig}} v 4.0},
  year = {2022},
  month = aug,
  url = {https://cidoc-crm.org/crmdig/sites/default/files/CRMdigv4.0.pdf},
  file = {/Users/mromanel/Zotero/storage/ISELCSXI/2022_Definition of CRMdig v 4.pdf}
}

@article{pellegrino_move_2023,
  title = {Move Cultural Heritage Knowledge Graphs in Everyone's Pocket},
  author = {Pellegrino, Maria Angela and Scarano, Vittorio and Spagnuolo, Carmine},
  year = {2023},
  month = jan,
  journal = {Semantic Web},
  volume = {14},
  number = {2},
  pages = {323--359},
  publisher = {IOS Press},
  issn = {1570-0844},
  doi = {10.3233/SW-223117},
  url = {https://content.iospress.com/articles/semantic-web/sw223117},
  urldate = {2025-03-26},
  abstract = {Last years witnessed a shift from the potential utility in digitisation to a crucial need to enjoy activities virtually. In fact, before 2019, data curators recognised the utility of performing data digitisation, while during the lockdown caused by t},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/RKNPRLDR/Pellegrino et al. - 2023 - Move cultural heritage knowledge graphs in everyon.pdf}
}

@article{peroni_documentinspired_2016,
  title = {A Document-Inspired Way for Tracking Changes of {{RDF}} Data},
  author = {Peroni, Silvio and Shotton, David and Vitali, Fabio},
  year = {2016},
  abstract = {There are several distinct ways to represent data drift in the Linked Open Data world. In this paper we introduce an approach for tracking data changes that has been used in the context of the OpenCitations Project. Such approach has been inspired by existing works on change tracking mechanisms in documents created through word-processors such as Microsoft Word and OpenOffice Writer.},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/LLVXJE5C/Peroni et al. - A document-inspired way for tracking changes of RD.pdf}
}

@misc{resig_using_nodate,
  title = {Using {{Computer Vision}} to {{Increase}} the {{Research Potential}} of {{Photo Archives}}},
  author = {Resig, John},
  url = {https://johnresig.com/research/computer-vision-photo-archives/},
  urldate = {2024-09-13},
  langid = {american},
  file = {/Users/mromanel/Zotero/storage/UEXMXCX8/computer-vision-photo-archives.html}
}

@article{sanderson_implementing_2023,
  title = {Implementing {{Linked Art}} in a {{Multi-Modal Database}} for {{Cross-Collection Discovery}}},
  author = {Sanderson, Robert},
  year = {2023},
  month = jul,
  journal = {Open Library of Humanities},
  publisher = {Open Library of the Humanities},
  doi = {10.16995/olh.15407},
  url = {https://www.scienceopen.com/document?vid=4ed87bce-331a-434e-838f-4164af56ca62},
  urldate = {2025-04-02},
  abstract = {{$<$}p xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="first" dir="auto" id="d1130220e63"{$>$}Yale University has implemented a knowledge graph based discovery system that brings together the various art, natural history, archival, conservation and bibliographic collections using Linked Open Usable Data standards such as Linked Art and IIIF. This system comprises more than 41 million records, which would expand to more than 2 billion RDF triples, and is thus at a similar scale to Europeana. This paper presents the lessons learned from the five year effort around the usability of linked data structures across the organization, the technologies needed to make use of the knowledge in a performant way, and the appropriate design paradigms for front end applications which make the graph easily and intuitively accessible to researchers and the public, including the necessity of consistency in data modeling, that records are an essential concept to maintain through multi-modal systems, and the use of hypertext and web caches to maintain the separation between systems. {$<$}/p{$>$}},
  file = {/Users/mromanel/Zotero/storage/6PU4E47V/Sanderson - 2023 - Implementing Linked Art in a Multi-Modal Database .pdf}
}

@incollection{schneider_computer_2023,
  title = {Computer {{Vision}} and {{Architectural History}} at {{Eye Level}}: {{Mixed Methods}} for {{Linking Research}} in the {{Humanities}} and in {{Information Technology}} ({{ArchiMediaL}})},
  shorttitle = {Computer {{Vision}} and {{Architectural History}} at {{Eye Level}}},
  booktitle = {Mixing {{Methods}}},
  author = {Mager, Tino and Khademi, Seyran and Siebes, Ronald and Gemert, Jan Van and Boer, Victor De and L{\"o}ffler, Beate and Hein, Carola},
  editor = {Schneider, Birgit and L{\"o}ffler, Beate and Mager, Tino and Hein, Carola},
  year = {2023},
  month = dec,
  pages = {125--144},
  publisher = {Bielefeld University Press},
  doi = {10.1515/9783839469132-014},
  url = {https://www.degruyter.com/document/doi/10.1515/9783839469132-014/html},
  urldate = {2024-09-11},
  copyright = {http://creativecommons.org/licenses/by/4.0},
  isbn = {978-3-8394-6913-2},
  file = {/Users/mromanel/Zotero/storage/PAESYFLP/Mager et al. - 2023 - Computer Vision and Architectural History at Eye L.pdf}
}

@article{smits_fully-searchable_2025,
  title = {A {{Fully-Searchable Multimodal Dataset}} of The\&nbsp;{{Illustrated London News}}, 1842\&ndash;1890},
  author = {Smits, Thomas and Warner, Bethany and Fyfe, Paul and Lee, Benjamin Charles Germain},
  year = {2025},
  month = feb,
  journal = {Journal of Open Humanities Data},
  volume = {11},
  number = {1},
  issn = {2059-481X},
  doi = {10.5334/johd.284},
  url = {https://openhumanitiesdata.metajnl.com/articles/10.5334/johd.284},
  urldate = {2025-02-06},
  abstract = {The~Journal of Open Humanities Data (JOHD)~aims to be a key part of a thriving community of scholars sharing humanities data. The journal features peer reviewed publications describing humanities research objects or techniques with high potential for reuse. Humanities subjects of interest to JOHD include, but are not limited to Art History, Classics, History, Library Science, Linguistics, Literature, Media Studies, Modern Languages, Music and musicology, Philosophy, Religious Studies, etc. Submissions that cross one or more of these traditional disciplines are particularly encouraged.},
  langid = {american},
  file = {/Users/mromanel/Zotero/storage/RXW263LV/Smits et al. - 2025 - A Fully-Searchable Multimodal Dataset of the&nbsp;.pdf}
}

@article{smits_multimodal_2023,
  title = {A Multimodal Turn in {{Digital Humanities}}. {{Using}} Contrastive Machine Learning Models to Explore, Enrich, and Analyze Digital Visual Historical Collections},
  author = {Smits, Thomas and Wevers, Melvin},
  year = {2023},
  month = sep,
  journal = {Digital Scholarship in the Humanities},
  volume = {38},
  number = {3},
  pages = {1267--1280},
  issn = {2055-7671},
  doi = {10.1093/llc/fqad008},
  url = {https://doi.org/10.1093/llc/fqad008},
  urldate = {2024-10-22},
  abstract = {Until recently, most research in the Digital Humanities (DH) was monomodal, meaning that the object of analysis was either textual or visual. Seeking to integrate multimodality theory into the DH, this article demonstrates that recently developed multimodal deep learning models, such as Contrastive Language Image Pre-training (CLIP), offer new possibilities to explore and analyze image--text combinations at scale. These models, which are trained on image and text pairs, can be applied to a wide range of text-to-image, image-to-image, and image-to-text prediction tasks. Moreover, multimodal models show high accuracy in zero-shot classification, i.e. predicting unseen categories across heterogeneous datasets. Based on three exploratory case studies, we argue that this zero-shot capability opens up the way for a multimodal turn in DH research. Moreover, multimodal models allow scholars to move past the artificial separation of text and images that was dominant in the field and analyze multimodal meaning at scale. However, we also need to be aware of the specific (historical) bias of multimodal deep learning that stems from biases in the training data used to train these models.},
  file = {/Users/mromanel/Zotero/storage/XUE4E2U3/Smits_Wevers_2023_A multimodal turn in Digital Humanities.pdf}
}

@article{theodoridou_modeling_2010,
  title = {Modeling and Querying Provenance by Extending {{CIDOC CRM}}},
  author = {Theodoridou, Maria and Tzitzikas, Yannis and Doerr, Martin and Marketakis, Yannis and Melessanakis, Valantis},
  year = {2010},
  month = apr,
  journal = {Distributed and Parallel Databases},
  volume = {27},
  number = {2},
  pages = {169--210},
  issn = {1573-7578},
  doi = {10.1007/s10619-009-7059-2},
  url = {https://doi.org/10.1007/s10619-009-7059-2},
  urldate = {2024-10-09},
  abstract = {This paper elaborates on the problem of modeling provenance for both physical and digital objects. In particular it discusses provenance according to OAIS (ISO 14721:2003) and how it relates with the conceptualization of CIDOC CRM ontology (ISO 21127:2006). Subsequently it introduces an extension of the CIDOC CRM ontology, able to capture the modeling and the query requirements regarding the provenance of digital objects. Over this extension the paper provides a number of indicative examples of modeling provenance in various domains. Subsequently, it introduces a number of indicative provenance query templates, and finally it describes an implementation using Semantic Web technologies.},
  langid = {english},
  keywords = {Artificial Intelligence,Digital presentation,Provenance modeling,Querying provenance information,Semantic web},
  file = {/Users/mromanel/Zotero/storage/L6IHJPPI/Theodoridou et al. - 2010 - Modeling and querying provenance by extending CIDO.pdf}
}

@article{westerby_annotating_2024,
  title = {Annotating {{Upstream}}: {{Digital Scholars}}, {{Art History}}, and the {{Interoperable Image}}},
  shorttitle = {Annotating {{Upstream}}},
  author = {Westerby, Matthew J.},
  year = {2024},
  month = nov,
  journal = {Open Library of Humanities},
  volume = {10},
  number = {2},
  publisher = {Open Library of Humanities},
  issn = {2056-6700},
  doi = {10.16995/olh.17217},
  url = {https://olh.openlibhums.org/article/id/17217/},
  urldate = {2025-04-28},
  abstract = {Written primarily from the position of an art historian engaged in digital research and data-intensive projects, this essay explores annotations on interoperable images and the possibility for annotations as ``thick data.'' Images and descriptive metadata can be used and re-used in any number of contexts, but annotations are contextual fragments of scholarly insights that do not translate easily across domains. While data models for web annotation are clearly defined in a technical sense, their implementation is socially motivated. This essay gives a very brief overview the ecosystem of IIIF annotations as outgrowths of sandbox projects and Open Access initiatives at art museums and libraries. I suggest that art historians should practice ``upstream annotation'' by maintaining the data that constitute their annotation outputs while acknowledging the sociotechnical affordances and ephemerality of annotation spaces.},
  copyright = {Copyright: {\copyright} 2024 The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  file = {/Users/mromanel/Zotero/storage/XJAGUZY5/Westerby - 2024 - Annotating Upstream Digital Scholars, Art History.pdf}
}

@misc{wiel_stakeholder_2024,
  title = {Stakeholder {{Engagement}} for {{Sustainable Open Research Data Support Services}}: {{Insights}} from {{Interviews}} and {{Surveys}} in {{Switzerland}}},
  shorttitle = {Stakeholder {{Engagement}} for {{Sustainable Open Research Data Support Services}}},
  author = {{\noopsort{wiel}}vd Wiel, Hester and Garassino, Francesco and Li, Zhixuan and {Fraga-Gonz{\'a}lez}, Gorka and Furrer, Eva and Held, Leonhard},
  year = {2024},
  month = dec,
  publisher = {OSF},
  doi = {10.31222/osf.io/3d5we},
  url = {https://osf.io/3d5we},
  urldate = {2025-01-08},
  abstract = {Over the past years, the concept of Open Research Data (ORD) has gained traction as part of broader Open Science initiatives. The benefits of ORD, such as increased cost-effectiveness, transparency, and visibility, are well documented. However, researchers often face barriers, which may be perceived rather than real, hindering the adoption of ORD practices. To address this challenge, we propose using ORD support services as sustainable enablers to stimulate cultural change around ORD. We engaged stakeholders across the University of Zurich and the larger Swiss ORD community to identify which services would best serve as sustainable enablers. After defining ORD support services and categorizing them into six key areas, we conducted surveys and interviews to gather insights on service preferences and barriers to ORD adoption. Our findings reveal a strong preference for simpler, lower-resource services among researchers, highlighting the need for user-friendly and easily accessible support. Experts emphasized the importance of professional data stewardship, robust Research Data Management practices, and customized support to address discipline-specific needs. By combining survey and interview results, we additionally provide a detailed overview of stakeholders' ideas and suggestions for each proposed support area. Our study results in three recommendations for academic institutions aiming to stimulate a cultural shift towards ORD. By focusing on findable, accessible, and user-friendly services, equipping researchers with fundamental RDM skills, and moving towards the professionalization of data stewardship to provide customized support, institutions can foster the adoption of ORD practices. Ultimately, these measures can enhance the impact and reproducibility of scientific research.},
  archiveprefix = {OSF},
  langid = {american},
  keywords = {Cultural change,Institutional policy,Open Research Data,Stakeholder engagement,Sustainable enablers},
  file = {/Users/mromanel/Zotero/storage/X3IYSGGC/Wiel et al. - 2024 - Stakeholder Engagement for Sustainable Open Resear.pdf}
}

@preamble{ "\providecommand{\noopsort}[1]{} " }
